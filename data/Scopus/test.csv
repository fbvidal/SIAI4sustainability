Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Molecular Sequence Numbers,Chemicals/CAS,Tradenames,Manufacturers,Funding Details,Funding Text 1,Funding Text 2,Funding Text 3,Funding Text 4,Funding Text 5,Funding Text 6,Funding Text 7,Funding Text 8,Funding Text 9,Funding Text 10,References,Correspondence Address,Editors,Sponsors,Publisher,Conference name,Conference date,Conference location,Conference code,ISSN,ISBN,CODEN,PubMed ID,Language of Original Document,Abbreviated Source Title,Document Type,Publication Stage,Open Access,Source,EID
"Kaur D., Uslu S., Rittichier K.J., Durresi A.","57209112293;57202760194;57232777900;57207529486;","Trustworthy Artificial Intelligence: A Review",2023,"ACM Computing Surveys","55","2","3491209","","",,2,"10.1145/3491209","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128190943&doi=10.1145%2f3491209&partnerID=40&md5=622d2c23d91ae624a63a320c7d89453b","University-Purdue University XXXXXnapolis, Computer and Information Science, 723 W Michigan St, XXXXXnapolis, IN  46202, United States of America","Kaur, D., XXXXXna University-Purdue University XXXXXnapolis, Computer and Information Science, 723 W Michigan St, XXXXXnapolis, IN  46202, United States; Uslu, S., XXXXXna University-Purdue University XXXXXnapolis, Computer and Information Science, 723 W Michigan St, XXXXXnapolis, IN  46202, United States of America; Rittichier, K.J., XXXXXna University-Purdue University XXXXXnapolis, Computer and Information Science, 723 W Michigan St, XXXXXnapolis, IN  46202, United States of America; Durresi, A., XXXXXna University-Purdue University XXXXXnapolis, Computer and Information Science, 723 W Michigan St, XXXXXnapolis, IN  46202, United States of America","Artificial intelligence (AI) and algorithmic decision making are having a profound impact on our daily lives. These systems are vastly used in different high-stakes applications like healthcare, business, government, education, and justice, moving us toward a more algorithmic society. However, despite so many advantages of these systems, they sometimes directly or indirectly cause harm to the users and society. Therefore, it has become essential to make these systems safe, reliable, and trustworthy. Several requirements, such as fairness, explainability, accountability, reliability, and acceptance, have been proposed in this direction to make these systems trustworthy. This survey analyzes all of these different requirements through the lens of the literature. It provides an overview of different approaches that can help mitigate AI risks and increase trust and acceptance of the systems by utilizing the users and society. It also discusses existing strategies for validating and verifying these systems and the current standardization efforts for trustworthy AI. Finally, we present a holistic view of the recent advancements in trustworthy AI to help the interested researchers grasp the crucial facets of the topic efficiently and offer possible future research directions. © 2022 Association for Computing Machinery.","acceptance; accountability; Artificial intelligence; black-box problem; explainability; explainable AI; fairness; machine learning; privacy; trustworthy AI","Data privacy; Ethical technology; Machine learning; Acceptance; Accountability; Algorithmics; Black boxes; Black-box problem; Explainability; Explainable artificial intelligence; Fairness; Privacy; Trustworthy artificial intelligence; Decision making",,,,,"National Science Foundation, NSF: 1547411; U.S. Department of Agriculture, USDA; National Institute of Food and Agriculture, NIFA: 2017-67003-26057","This work was partially supported by the National Science Foundation (NSF) under grant 1547411 and by the U.S. Department of Agriculture (USDA), National Institute of Food and Agriculture (NIFA) (award 2017-67003-26057) via an interagency partnership between USDA-NIFA and the NSF on the research program Innovations at the Nexus of Food, Energy, and Water Systems. Authors’ address: D. Kaur, S. Uslu, K. J. Rittichier, and A. Durresi, XXXXXna University-Purdue University XXXXXnapolis, Computer & Information Science, 723 W Michigan St, XXXXXnapolis, IN 46202; emails: {davikaur, suslu, krittich}@iu.edu, adurresi@iupui.edu. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. © 2022 Association for Computing Machinery. 0360-0300/2022/01-ART39 $15.00 https://doi.org/10.1145/3491209",,,,,,,,,,"Achinstein, P., (1983) The Nature of Explanation, , Oxford University Press on Demand; Adadi, A., Berrada, M., Peeking inside the black-box: A survey on Explainable Artificial Intelligence (XAI) (2018) Ieee Access, 6, pp. 52138-52160. , 2018; Agarwal, A., Lohia, P., Nagar, S., Dey, K., Saha, D., (2018) Automated Test Generation to Detect Individual Discrimination in Ai Models, , https://arxiv.org/abs/1809.03260, 2018; Angwin, J., Larson, J., Mattu, S., Kirchner, L., Machine bias (2016) ProPublica, , May 23, 2016; Barredo Arrieta, A., Díaz-Rodríguez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado, A., García, S., Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI (2020) Information Fusion, 58, pp. 82-115. , 2020; Arya, V., Bellamy E., R.K., Chen, P., Dhurandhar, A., Hind, M., Hoffman, S.C., Houde, S., One explanation does not fit all: A toolkit and taxonomy of AI explainability techniques (2019) ArXiv E-prints, , https://arxiv.org/abs/1909.03012, 2019, ArXiv-1909; Awasthi, P., Kleindessner, M., Morgenstern, J., Equalized odds postprocessing under imperfect group information (2020) Proceedings of the International Conference on Artificial Intelligence and Statistics, pp. 1770-1780; Ba, S., Establishing online trust through a community responsibility system (2001) Decision Support Systems, 31 (3), pp. 323-336. , 2001; Bach, S., Binder, A., Montavon, G., Klauschen, F., Müller, K., Samek, W., On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation (2015) PLoS One, 10 (7), p. 130140. , 2015; Backurs, A., Indyk, P., Onak, K., Schieber, B., Vakilian, A., Wagner, T., Scalable fair clustering (2019) Proceedings of the International Conference on Machine Learning, pp. 405-413; Trust Barometer, E., (2019) Edelman Trust Barometer Global Report, , https://www.edelman.com/sites/g/files/aatuss191/files/2019-02/2019-Edelman-Trust-Barometer-Global-Report.pdf, Retrieved November 2, 2021 from; Beaudouin, V., Bloch, I., Bounie, D., Clémençon, S., D'Alché Buc, F., Eagan, J., Maxwell, W., Parekh, J., (2020) Flexible and Context-specific Ai Explainability: A Multidisciplinary Approach, , 2020, SSRN 3559477; Bechavod, Y., Ligett, K., (2017) Penalizing Unfairness in Binary Classification, , https://arxiv.org/pdf/1707.00044.pdf, 2017; Bellamy E., R.K., Dey, K., Hind, M., Hoffman, S.C., Houde, S., Kannan, K., Lohia, P., AI Fairness 360: An extensible toolkit for detecting and mitigating algorithmic bias (2019) Ibm Journal of Research and Development, 63 (4-5), p. 15. , 2019, Article 4; Berghel, H., Equifax and the latest round of identity theft roulette (2017) Computer, 50 (12), pp. 72-76. , 2017; Berk, R., Heidari, H., Jabbari, S., Joseph, M., Kearns, M., Morgenstern, J., Neel, S., Roth, A., (2017) A Convex Framework for Fair Regression, , https://arxiv.org/abs/1706.02409, 2017; Bhatt, U., Xiang, A., Sharma, S., Weller, A., Taly, A., Jia, Y., Ghosh, J., Eckersley, P., Explainable machine learning in deployment (2020) Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 648-657; Binns, R., Van Kleek, M., Veale, M., Lyngs, U., Zhao, J., Shadbolt, N., It's reducing a human being to a percentage' perceptions of justice in algorithmic decisions (2018) Proceedings of the 2018 Chi Conference on Human Factors in Computing Systems, pp. 1-14; Black, E., Yeom, S., Fredrikson, M., FlipTest: Fairness testing via optimal transport (2020) Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 111-121; Bogen, M., Rieke, A., (2018) HelpWanted: An Examination of Hiring Algorithms, Equity, , Technical Report. Upturn; Bolukbasi, T., Chang, K., Saligrama Venkatesh Zou, J.Y., Kalai, A.T., Man is to computer programmer as woman is to homemaker? Debiasing word embeddings (2016) Advances in Neural Information Processing Systems, pp. 4349-4357; Bourtoule, L., Chandrasekaran, V., Choquette-Choo, ChristopherA., Jia, H., Travers, A., Zhang, B., Lie, D., Papernot, N., Machine unlearning (2021) Proceedings of the 2021 Ieee Symposium on Security and Privacy (SP'21), pp. 141-159. , IEEE, Los Alamitos, CA; Boyens, J., Paulsen, C., Moorthy, R., Bartol, N., Shankles, S.A., Supply chain risk management practices for federal information systems and organizations (2015) Nist Special Publication, 800 (161), p. 32. , 2015; Braithwaite, V., Beyond the bubble that is Robodebt: How governments that lose integrity threaten democracy (2020) Australian Journal of Social Issues, 55 (3), pp. 242-259. , 2020; Brennan-Marquez, K., Plausible cause: Explanatory standards in the age of powerful machines (2017) Vanderbilt Law Review, 70, p. 1249. , 2017; Broeders, D., Schrijvers, E., Van Der Sloot, B., Van Brakel, R., De Hoog, J., Hirsch Ballin, E., Big data and security policies: Towards a framework for regulating the phases of analytics and use of big data (2017) Computer Law & Security Review, 33 (3), pp. 309-323. , 2017; Brunet, M., Alkalay-Houlihan, C., Anderson, A., Zemel, R., Understanding the origins of bias in word embeddings (2019) Proceedings of the International Conference on Machine Learning, pp. 803-811; Bundesamt, F., Study: ""An Investigation into the Performance of Facial Recognition Systems Relative to Their Planned Use in Photo Identification Documents-BioP I (2004) Bundesamt fur Sicherheit in der Informationstechnik; Bunt, A., Lount, M., Lauzon, C., Are explanations always important? A study of deployed, low-cost intelligent interactive systems (2012) Proceedings of the 2012 Acm International Conference on Intelligent User Interfaces, pp. 169-178; Buolamwini, J., Gebru, T., Gender shades: Intersectional accuracy disparities in commercial gender classification (2018) Proceedings of the Conference on Fairness, Accountability, and Transparency, pp. 77-91; Burke, B., Cearley, D., Jones, N., Smith, D., Chandrasekaran, A., Lu, C.K., Panetta, K., (2019) Gartner Top 10 Strategic Technology Trends for 2020-Smarter with Gartner, , https://www.gartner.com/smarterwithgartner/gartner-top-10-strategic-technology-trends-for-2020/, Retrieved November 2, 2021 from; Callaway, E., DeepMind's AI predicts structures for a vast trove of proteins (2021) Nature, 595 (7869), p. 635. , 2021; Calmon, F., Wei, D., Vinzamuri, B., Natesan Ramamurthy, K., Varshney, K.R., Optimized pre-processing for discrimination prevention (2017) Advances in Neural Information Processing Systems, pp. 3992-4001; Campione, C., (2020) The Dark Nudge Era: Cambridge Analytica, Digital Manipulation in Politics, and the Fragmentation of Society, , Bachelor's Thesis. Luiss Guido Carli; Cao, Y., Yang, J., Towards making systems forget with machine unlearning (2015) Proceedings of the 2015 Ieee Symposium on Security and Privacy, pp. 463-480. , IEEE, Los Alamitos, CA; Casalicchio, G., Molnar, C., Bischl, B., Visualizing the feature importance for black box models (2018) Proceedings of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 655-670; Castelvecchi, D., Can we open the black box of AI? (2016) Nature News, 538 (7623), p. 20. , 2016; Elisa Celis, L., Deshpande, A., Kathuria, T., Vishnoi, N.K., (2016) How to Be Fair and Diverse?, , 2016; Chen, H., Umar Hussain, S., Boemer, F., Stapf, E., Reza Sadeghi, A., Koushanfar, F., Cammarota, R., Developing privacy-preserving AI systems: The lessons learned (2020) Proceedings of the 2020 57th ACM/IEEE Design Automation Conference (DAC'20), pp. 1-4. , IEEE, Los Alamitos, CA; Chen, T., Guestrin, C., XGBoost: A scalable tree boosting system (2016) Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining, pp. 785-794; Yueh Chen, T., Kuo, F., Liu, H., Poon, P., Towey, D., Tse, T.H., Quan Zhou, Z., Metamorphic testing: A review of challenges and opportunities (2018) Acm Computing Surveys, 51 (1), pp. 1-27. , 2018; Chouldechova, A., Benavides-Prado, D., Fialko, O., Vaithianathan, R., A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions (2018) Proceedings of the Conference on Fairness, Accountability, and Transparency, pp. 134-148; Commission, E., (2020) White Paper on Artificial Intelligence-A European Approach to Excellence and Trust, , European Commission; Corbett-Davies, S., Pierson, E., Feller, A., Goel, S., Huq, A., Algorithmic decision making and the cost of fairness (2017) Proceedings of the 23rd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining, pp. 797-806; Crawford, K., Can an algorithm be agonistic? Ten scenes from life in calculated publics (2016) Science, Technology, & Human Values, 41 (1), pp. 77-92. , 2016; Crawford, K., (2021) The Atlas of Ai, , Yale University Press; Silveira Cruz, B., De Oliveira Dias, M., Crashed Boeing 737-MAX: Fatalities or malpractice? (2020) Gsj, 8 (1), pp. 2615-2624. , 2020; Daly, A., Kate Devitt, S., Mann, M., (2021) Ai Ethics Needs Good Data, , https://arxiv.org/ftp/arxiv/papers/2102/2102.07333.pdf, 2021; Danny Tobey, M.D., (2019) Explainability: Where Ai and Liability Meet: Actualités: Dla Piper Global Law Firm, , https://www.dlapiper.com/fr/france/insights/publications/2019/02/explainabilitywhere-ai-and-liability-meet/, Retrieved November 2, 2021 from; Dastin, J., Amazon scraps secret AI recruiting tool that showed bias against women (2018) Reuters, , https://www.reuters.com; Daugherty, P.R., JamesWilson, H., (2018) Human+ Machine: ReimaginingWork in the Age of Ai, , Harvard Business Press; Laat De, P.B., Algorithmic decision-making based on machine learning from big data: Can transparency restore accountability? (2018) Philosophy & Technology, 31 (4), pp. 525-541. , 2018; Kate Devitt, S., Trustworthiness of autonomous systems (2018) Foundations of Trusted Autonomy, pp. 161-184. , Springer, Cham, Switzerland; Dignum, V., Responsible artificial intelligence: Designing AI for human values (2017) Ict Discoveries, 1, pp. 1-8. , 2017; Dobson, J.E., Can an algorithm be disturbed? Machine learning, intrinsic criticism, and the digital humanities (2015) College Literature, 42 (4), pp. 543-564. , 2015; Dove, G., Halskov, K., Forlizzi, J., Zimmerman, J., UX design innovation: Challenges forworking with machine learning as a design material (2017) Proceedings of the 2017 Chi Conference on Human Factors in Computing Systems, pp. 278-288; Moritz Hardt, C., Pitassi, T., Reingold, O., Zemel, R., Fairness through awareness (2012) Proceedings of the 3rd Innovations in Theoretical Computer Science Conference, pp. 214-226; Dwork, C., Immorlica, N., Tauman Kalai, A., Leiserson, M., Decoupled classifiers for groupfair and efficient machine learning (2018) Proceedings of the Conference on Fairness, Accountability, and Transparency, pp. 119-133; Dworkin, M., Recommendation for block cipher modes of operation: Methods for format-preserving encryption (2016) Nist Special Publication, 800, p. 38G. , 2016; (2018) Ethics Guidelines for Trustworthy Ai, , https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai, European Commission, Retrieved November 2, 2021 from; Elliott, A., (2019) The Culture of AI: Everyday Life and the Digital Revolution, , Routledge; Fan, W., Liu, J., Zhu, S., Pardalos, P.M., Investigating the impacting factors for the healthcare professionals to adopt artificial intelligence-based medical diagnosis support system (AIMDSS) (2020) Annals of Operations Research, 294 (1), pp. 567-592. , 2020; Feldman, M., Friedler, S.A., Moeller, J., Scheidegger, C., Venkatasubramanian, S., Certifying and removing disparate impact (2015) Proceedings of the 21th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining, pp. 259-268; Feuerriegel, S., Dolata, M., Schwabe, G., Fair AI: Challenges and opportunities (2020) Business & Information Systems Engineering, 62 (1), pp. 1-7. , 2020; Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F., Efficient and robust automated machine learning (2015) Advances in Neural Information Processing Systems, pp. 2962-2970; Fisher, A., Rudin, C., Dominici, F., (2018) All Models Are Wrong but Many Are Useful: Variable Importance for Black-box, Proprietary, or Misspecified Prediction Models, Using Model Class Reliance, pp. 237-246. , 2018; Flores, A.W., Bechtel, K., Lowenkamp, C.T., False positives, false negatives, and false analyses: A rejoinder to machine bias: There's software used across the country to predict future criminals. and it's biased against blacks (2016) Federal Probation, 80, p. 38. , 2016; Floridi, L., Cowls, J., A unified framework of five principles for AI in society (2019) Hdsr, 1 (1). , 2019; Floridi, L., Cowls, J., King, T.C., Taddeo, M., How to design AI for social good: Seven essential factors (2020) Science and Engineering Ethics, 26 (3), pp. 1771-1796. , 2020; (2015) The Pathway to Driverless Cars: A Code of Practice for Testing, , Department for Transport UK; Jose Gacto, M., Alcalá, R., Herrera, F., Interpretability of linguistic fuzzy rule-based systems: An overview of interpretability measures (2011) Information Sciences, 181 (20), pp. 4340-4360. , 2011; Gajane, P., Pechenizkiy, M., (2017) On Formalizing Fairness in Prediction with Machine Learning, , 2017; Galdon Clavell, G., Martín Zamorano, M., Castillo, C., Smith, O., Matic, A., Auditing algorithms: On lessons learned and the risks of data minimization (2020) Proceedings of the AAAI/ Acm Conference on AI, Ethics, and Society, pp. 265-271; Garfinkel, S.L., (2015) De-Identification of Personal Information, , National Institute of Standards and Technology; Gebru, T., Morgenstern, J., Vecchione, B., Wortman Vaughan, J., Wallach, H., Daumé, H., Crawford, K., (2018) Datasheets for Datasets, , https://arxiv.org/abs/1803.09010, 2018; Geyer, R.C., Klein, T., Nabi, M., (2017) Differentially Private Federated Learning: A Client Level Perspective, , 2017; Ghorbani, A., Zou Y., J.James, Kim, B., Towards automatic concept-based explanations (2019) Advances in Neural Information Processing Systems, pp. 9277-9286; Goodman, B., Flaxman, S., European Union regulations on algorithmic decision-making and a ""right to explanation (2017) Ai Magazine, 38 (3), pp. 50-57. , 2017; Granovetter, M., Economic action and social structure: The problem of embeddedness (2018) The Sociology of Economic Life, pp. 22-45. , Routledge; Greene, C., Stavins, J., Did the target data breach change consumer assessments of payment card security? (2017) Journal of Payments Strategy & Systems, 11 (2), pp. 121-133. , 2017; Gunning, D., (2017) Explainable Artificial Intelligence (XAI), , Defense Advanced Research Projects Agency; Gursoy, D., Chi, O., Lu, L., Nunkoo, R., Consumers acceptance of artificially intelligent (AI) device use in service delivery (2019) International Journal of Information Management, 49, pp. 157-169. , 2019; Hagendorff, T., The ethics of AI ethics: An evaluation of guidelines (2020) Minds and Machines, 30 (1), pp. 99-120. , 2020; Hailesilassie, T., (2016) Rule Extraction Algorithm for Deep Neural Networks: A Review, , 2016; Hao, M., Li, H., Luo, X., Xu, G., Yang, H., Liu, S., Efficient and privacy-enhanced federated learning for industrial artificial intelligence (2019) Ieee Transactions on Industrial Informatics, 16 (10), pp. 6532-6542. , 2019; Hardt, M., Price, E., Srebro, N., Equality of opportunity in supervised learning (2016) Advances in Neural Information Processing Systems, pp. 3315-3323; Haufe, S., Meinecke, F., Görgen, K., Dähne, S., Haynes, J., Blankertz, B., Bießmann, F., On the interpretation of weight vectors of linear models in multivariate neuroimaging (2014) Neuroimage, 87, pp. 96-110. , 2014; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in a Neural Network, , https://arxiv.org/abs/1503.02531, 2015; Hohman, F., Wongsuphasawat, K., Beth Kery, M., Patel, K., Understanding and visualizing data iteration in machine learning (2020) Proceedings of the 2020 Chi Conference on Human Factors in Computing Systems, pp. 1-13; Holland, S., Hosny, A., Newman, S., (2020) The Dataset Nutrition Label, , 2020; Huang, L., Vishnoi, N., Stable and fair classification (2019) Proceedings of the International Conference on Machine Learning, pp. 2879-2890; (2020) Information Technology-Artificial Intelligence-Overview of Trustworthiness in Artificial Intelligence, , ISO 24028: 2020, Standard. International Organization for Standardization; Jacovi, A., Sar Shalom, O., Goldberg, Y., (2018) Understanding Convolutional Neural Networks for Text Classification, , https://arxiv.org/abs/1809.08037, 2018; Jiang, Z., Gao, W., Wang, L., Xiong, X., Zhang, Y., Wen, X., Luo, C., HPC AI500: A benchmark suite for HPC AI systems (2018) Proceedings of the International Symposium on Benchmarking, Measuring, and Optimization, pp. 10-22; Jobin, A., Ienca, M., Vayena, E., The global landscape of AI ethics guidelines (2019) Nature Machine Intelligence, 1 (9), pp. 389-399. , 2019; Kaminski, M.E., Malgieri, G., Multi-layered explanations from algorithmic impact assessments in the GDPR (2020) Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 68-79; Kamiran, F., Calders, T., Data preprocessing techniques for classification without discrimination (2012) Knowledge and Information Systems, 33 (1), pp. 1-33. , 2012; Kamiran, F., Calders, T., Pechenizkiy, M., Discrimination aware decision tree learning (2010) Proceedings of the 2010 Ieee International Conference on Data Mining, pp. 869-874. , IEEE, Los Alamitos, CA; Kamishima, T., Akaho, S., Asoh, H., Sakuma, J., Fairness-aware classifier with prejudice remover regularizer (2012) Proceedings of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 35-50; Kaplan, A., Haenlein, M., Siri, Siri, in my hand: Who's the fairest in the land? on the interpretations, illustrations, and implications of artificial intelligence (2019) Business Horizons, 62 (1), pp. 15-25. , 2019; Kaur, D., Uslu, S., Durresi, A., Trust-based security mechanism for detecting clusters of fake users in social networks (2019) Proceedings of TheWorkshops of the International Conference on Advanced Information Networking and Applications, pp. 641-650; Kaur, D., Uslu, S., Durresi, A., Requirements for trustworthy artificial intelligence-A review (2020) Proceedings of the International Conference on Network-Based Information Systems, pp. 105-115; Kaur, D., Uslu, S., Durresi, A., Badve, S., Dundar, M., Trustworthy explainability acceptance: A newmetric to measure the trustworthiness of interpretable AImedical diagnostic systems (2021) Proceedings of the International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS'21); Kaur, D., Uslu, S., Durresi, A., Mohler, G., Carter, J.G., Trust-based humanmachine collaboration mechanism for predicting crimes (2020) Proceedings of the International Conference on Advanced Information Networking and Applications, pp. 603-616; Kemp, D., Vanclay, F., Human rights and impact assessment: Clarifying the connections in practice (2013) Impact Assessment and Project Appraisal, 31 (2), pp. 86-96. , 2013; Kerschbaum, F., Frequency-hiding order-preserving encryption (2015) Proceedings of the 22nd Acm Sigsac Conference on Computer and Communications Security, pp. 656-667; Khalil, M., Ebner, M., De-identification in learning analytics (2016) Journal of Learning Analytics, 3 (1), pp. 129-138. , 2016; Kim, B., Khanna, R., Koyejo, O.O., Examples are not enough, learn to criticize! Criticism for interpretability (2016) Advances in Neural Information Processing Systems, pp. 2280-2288; Kim, B., Rudin, C., Shah, J.A., The Bayesian case model: A generative approach for case-based reasoning and prototype classification (2014) Advances in Neural Information Processing Systems, pp. 1952-1960; Kim, B., Justin Gilmer, M., Cai, C., Fernanda Viegas, J., Sayres, R., Interpretability beyond feature attribution: Quantitative Testing with Concept Activation Vectors (TCAV) (2018) Proceedings of the International Conference on Machine Learning, pp. 2668-2677; Kim, P.T., Auditing algorithms for discrimination (2017) University of Pennsylvania Law Review Online, 166, p. 189. , 2017; Knauf, R., Gonzalez, A.J., Abel, T., A framework for validation of rule-based systems (2002) Ieee Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 32 (3), pp. 281-295. , 2002; Kocielnik, R., Amershi, S., Bennett, P.N., Will you accept an imperfect AI? Exploring designs for adjusting end-user expectations of ai systems (2019) Proceedings of the 2019 Chi Conference on Human Factors in Computing Systems, pp. 1-14; Koh, P., Liang, P., Understanding black-box predictions via influence functions (2017) Proceedings of the International Conference on Machine Learning, pp. 1885-1894; Kohli, P., Chadha, A., Enabling pedestrian safety using computer vision techniques: A case study of the 2018 Uber Inc. self-driving car crash (2019) Proceedings of the Future of Information and Communication Conference, pp. 261-279; Kroll, J.A., Barocas, S., Felten, E.W., Reidenberg, J.R., Robinson, D.G., Yu, H., Accountable algorithms (2016) University of Pennsylvania Law Review, 165, p. 633. , 2016; Kumar, A., Braud, T., Tarkoma, S., Hui, P., Trustworthy AI in the age of pervasive computing and big data (2020) Proceedings of the 2020 Ieee International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops'20), pp. 1-6. , IEEE, Los Alamitos, CA; Kusner, M.J., Loftus, J., Russell, C., Silva, R., Counterfactual fairness (2017) Advances in Neural Information Processing Systems, pp. 4066-4076; LaBrie, R.C., Steinke, G., Towards a framework for ethical audits of AI algorithms (2019) Proceedings of the Conference on Data Science and Analytics for Decision Support; Lakkaraju, H., Bach, S.H., Leskovec, J., Interpretable decision sets: A joint framework for description and prediction (2016) Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining, pp. 1675-1684; Lee, T., Molloy, I.M., Su, D., (2019) Protecting Cognitive Systems from Model Stealing Attacks, , US Patent App. 15/714, 514; Legg, S., Hutter, M., A collection of definitions of intelligence (2007) Frontiers in Artificial Intelligence and Applications, 157, p. 17. , 2007; Lepri, B., Oliver, N., Letouzé, E., Pentland, A., Vinck, P., Fair, transparent, and accountable algorithmic decision-making processes (2018) Philosophy & Technology, 31 (4), pp. 611-627. , 2018; Li, N., Li, T., Venkatasubramanian, S., T-Closeness: Privacy beyond k-anonymity and Ldiversity (2007) Proceedings of the 2007 Ieee 23rd International Conference on Data Engineering, pp. 106-115. , IEEE, Los Alamitos, CA; Li, T., Kumar Sahu, A., Talwalkar, A., Smith, V., Federated learning: Challenges, methods, and future directions (2020) Ieee Signal Processing Magazine, 37 (3), pp. 50-60. , 2020; Lindvall, M., Ganesan, D., Ardal, R., Wiegand, R.E., Metamorphic model-based testing applied on NASA DAT-An experience report (2015) Proceedings of the 2015 IEEE/ACM 37th International Conference on Software Engineering, 2, pp. 129-138. , IEEE, Los Alamitos, CA; Lundberg, S.M., Lee, S., A unified approach to interpreting model predictions (2017) Advances in Neural Information Processing Systems, pp. 4765-4774; Thanh Luong, B., Ruggieri, S., Turini, F., K-NN as an implementation of situation testing for discrimination discovery and prevention (2011) Proceedings of the 17th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining, pp. 502-510; MacHanavajjhala, A., Kifer, D., Gehrke, J., Venkitasubramaniam, M., L-Diversity: Privacy beyond k-anonymity (2007) Acm Transactions on Knowledge Discovery from Data, 1 (1), p. 3. , 2007; Marcus, G., Davis, E., (2019) Rebooting AI: Building Artificial Intelligence We Can Trust, , Vintage; Marr, B., Is artificial intelligence dangerous? 6 AI risks everyone should know about (2018) Forbes, , 2018; Martin, K., Ethical implications and accountability of algorithms (2019) Journal of Business Ethics, 160 (4), pp. 835-850. , 2019; McMahan, B., Moore, E., Ramage, D., Hampson, S., Aguera Arcas, B., Communicationefficient learning of deep networks from decentralized data (2017) Artificial Intelligence and Statistics. Pmlr, pp. 1273-1282; McQuillan, D., People's councils for ethical machine learning (2018) Social Media+ Society, 4 (2), p. 2. , 2018; Mehrabi, N., Morstatter, F., Peng, N., Galstyan, A., Debiasing community detection: The importance of lowly connected nodes (2019) Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM'19), pp. 509-512. , IEEE, Los Alamitos, CA; Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., Galstyan, A., A survey on bias and fairness in machine learning (2021) Acm Computing Surveys, 54 (6), pp. 1-35. , 2021; Krishna Menon, A., Williamson, R.C., The cost of fairness in binary classification (2018) Proceedings of the Conference on Fairness, Accountability, and Transparency, pp. 107-118; Metcalf, J., Moss, E., Anne Watkins, E., Singh, R., Clare Elish, M., Algorithmic impact assessments and accountability: The co-construction of impacts (2021) Proceedings of the 2021 Acm Conference on Fairness, Accountability, and Transparency, pp. 735-746; Miller, T., Explanation in artificial intelligence: Insights from the social sciences (2019) Artificial Intelligence, 267, pp. 1-38. , 2019; Mothilal, R.K., Sharma, A., Tan, C., Explaining machine learning classifiers through diverse counterfactual explanations (2020) Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 607-617; Mullen, J., (2015) Google Rushes to Fix Software That Served Up Racial Slur, , https://www.cnn.com/2015/07/02/tech/google-image-recognition-gorillas-tag/, Retrieved November 2, 2021 from; Murphy, P.M., Pazzani, M.J., ID2-of-3: Constructive induction of M-of-N concepts for discriminators in decision trees (1991) Machine Learning Proceedings, 1991, pp. 183-187. , Elsevier; Nambiar, R., Towards an industry standard for benchmarking artificial intelligence systems (2018) Proceedings of the 2018 Ieee 34th International Conference on Data Engineering (ICDE'18), pp. 1679-1680. , IEEE, Los Alamitos, CA; Neyland, D., Bearing account-able witness to the ethical algorithmic system (2016) Science, Technology, & Human Values, 41 (1), pp. 50-76. , 2016; Ngan, M., Grother, P.J., Ngan, M., (2015) Face Recognition Vendor Test (FRVT) Performance of Automated Gender Classification Algorithms, , U.S. Department of Commerce, National Institute of Standards and Technology; Nicodeme, C., Build confidence and acceptance of AI-based decision support systems-Explainable and liable AI (2020) Proceedings of the 2020 13th International Conference on Human System Interaction (HSI'20), pp. 20-23. , IEEE, Los Alamitos, CA; Obermeyer, Z., Powers, B., Vogeli, C., Mullainathan, S., Dissecting racial bias in an algorithm used to manage the health of populations (2019) Science, 366 (6464), pp. 447-453. , 2019; (2021) Nist Proposes Method for Evaluating User Trust in Artificial Intelligence Systems, , https://www.nist.gov/news-events/news/2021/05/nistproposes-method-evaluating-user-trust-artificial-intelligence-systems, National Institute of Standards and Technology, Retrieved November 2, 2021 from; (2021) Artificial Intelligence: An Accountability Framework for Federal Agencies and Other Entities, , https://www.gao.gov/products/gao-21-519sp, U.S. Government Accountability Office, Retrieved November 2, 2021 from; Olteanu, A., Castillo, C., Diaz, F., Kiciman, E., Social data: Biases, methodological pitfalls, and ethical boundaries (2019) Frontiers in Big Data, 2, p. 13. , 2019; Ostrom, A.L., Fotheringham, D., Jo Bitner, M., Customer acceptance of AI in service encounters: Understanding antecedents and consequences (2019) Handbook of Service Science, 2, pp. 77-103. , Springer; Pauleen, D.J., Rooney, D., Intezari, A., Big data, little wisdom: Trouble brewing? Ethical implications for the information systems discipline (2017) Social Epistemology, 31 (4), pp. 400-416. , 2017; Perner, P., How to interpret decision trees? (2011) Proceedings of the Industrial Conference on Data Mining, pp. 40-55; Pichai, S., AI at Google: Our principles (2018) The Keyword, , June 7, 2018; Poier, S., Clean and green-The volkswagen emissions scandal: Failure of corporate governance? (2020) Problemy Ekorozwoju, 15 (2), pp. 33-39. , 2020; Quadrianto, N., Sharmanska, V., Recycling privileged learning and distribution matching for fairness (2017) Advances in Neural Information Processing Systems, pp. 677-688; Rahwan, I., Society-in-the-loop: Programming the algorithmic social contract (2018) Ethics and Information Technology, 20 (1), pp. 5-14. , 2018; Raita, E., Oulasvirta, A., Too good to be bad: Favorable product expectations boost subjective usability ratings (2011) Interacting with Computers, 23 (4), pp. 363-371. , 2011; Deborah Raji, I., Smart, A., White, R.N., Mitchell, M., Gebru, T., Hutchinson, B., Smith-Loud, J., Barnes, P., Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing (2020) Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 33-44; Reed, C., How should we regulate artificial intelligence? (2018) Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 376 (2128), p. 20170360. , 2018; Tulio Ribeiro, M., Singh, S., Guestrin, C., Why should I trust you?"" Explaining the predictions of any classifier (2016) Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining, pp. 1135-1144; Ribera, M., Lapedriza, A., Can we do better explanations? A proposal of user-centered explainable AI (2019) Proceedings of the Iui Workshops; Ritchie, S., (2017) Privacy Impact Assessment System and Associated Methods, , US Patent App. 15/459, 909; Rocher, L., Hendrickx, J.M., De Montjoye, Y., Estimating the success of re-identifications in incomplete datasets using generative models (2019) Nature Communications, 10 (1), pp. 1-9. , 2019; Roselli, D., Matthews, J., Talagala, N., Managing bias in AI (2019) Companion Proceedings of the 2019 World Wide Web Conference, pp. 539-544; Rosenquist, M., (2020) There Is No Easy Fix to Ai Privacy Problems, , https://www.helpnetsecurity.com/2020/01/23/ai-privacy-problems/, Retrieved November 2, 2021 from; Rotter, J.B., A new scale for the measurement of interpersonal trust (1967) Journal of Personality, 35 (4), pp. 651-665. , 1967; Ruan, Y., Zhang, P., Alfantoukh, L., Durresi, A., Measurement theory-based trust management framework for online social communities (2017) Acm Transactions on Internet Technology, 17 (2), pp. 1-24. , 2017; Ruggieri, S., Using t-closeness anonymity to control for non-discrimination (2014) Transactions on Data Privacy, 7 (2), pp. 99-129. , 2014; Sablayrolles, A., Douze, M., Schmid, C., Jégou, H., Radioactive data: Tracing through training (2020) Proceedings of the International Conference on Machine Learning, pp. 8326-8335; Saleiro, P., Kuester, B., Hinkson, L., London, J., Stevens, A., Anisfeld, A., Rodolfa, K.T., Ghani, R., (2018) Aequitas: A Bias and Fairness Audit Toolkit, , https://arxiv.org/abs/1811.05577, 2018; Samadi, S., Tantipongpipat, U., Morgenstern, J.H., Singh, M., Vempala, S., The price of fair PCA: One extra dimension (2018) Advances in Neural Information Processing Systems, pp. 10976-10987; Samek, W., Müller, K., Towards explainable artificial intelligence (2019) Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, pp. 5-22. , Springer; Sandvig, C., Hamilton, K., Karahalios, K., Langbort, C., Auditing algorithms: Research methods for detecting discrimination on Internet platforms (2014) Data and Discrimination: Converting Critical Concerns into Productive Inquiry, 22, pp. 1-23. , 2014; Sanneman, L., Shah, J.A., A situation awareness-based framework for design and evaluation of explainable AI (2020) Proceedings of the International Workshop on Explainable, Transparent, Autonomous Agents and Multi-Agent Systems, pp. 94-110; Santos, F.P., Santos, F.C., Paiva, A., Pacheco, J.M., Evolutionary dynamics of group fairness (2015) Journal of Theoretical Biology, 378, pp. 96-102. , 2015; Ani Saxena, N., Huang, K., DeFilippis, E., Radanovic, G., Parkes, D.C., Liu, Y., How do fairness definitions fare? Examining public attitudes towards algorithmic definitions of fairness (2019) Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society, pp. 99-106; Segura, S., Towey, D., Quan Zhou, Z., Yueh Chen, T., Metamorphic testing: Testing the untestable (2018) Ieee Software, 37 (3), pp. 46-53. , 2018; Shi, L., Wei, F., Liu, S., Tan, L., Lian, X., Zhou, M.X., Understanding text corpora with multiple facets (2010) Proceedings of the 2010 Ieee Symposium on Visual Analytics Science and Technology, pp. 99-106. , IEEE, Los Alamitos, CA; Shin, D., The effects of explainability and causability on perception, trust, and acceptance: Implications for explainable AI (2021) International Journal of Human-Computer Studies, 146, p. 102551. , 2021; Shin, D., Jin Park, Y., Role of fairness, accountability, and transparency in algorithmic affordance (2019) Computers in Human Behavior, 98, pp. 277-284. , 2019; Smilkov, D., Thorat, N., Nicholson, C., Reif, E., Viégas, F.B., Wattenberg, M., (2016) Embedding Projector: Interactive Visualization and Interpretation of Embeddings, , https://arxiv.org/abs/1611.05469, 2016; Smuha, N.A., The eu approach to ethics guidelines for trustworthy artificial intelligence (2019) Computer Law Review International, 20 (4), pp. 97-106. , 2019; Sohn, K., Kwon, O., Technology acceptance theories and factors influencing artificial intelligence-based intelligent products (2020) Telematics and Informatics, 47, p. 101324. , 2020; Sojda, R.S., Empirical evaluation of decision support systems: Needs, definitions, potential methods, and an example pertaining to waterfowl management (2007) Environmental Modelling & Software, 22 (2), pp. 269-277. , 2007; Sokol, K., Flach, P., Explainability fact sheets: A framework for systematic assessment of explainable approaches (2020) Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 56-67; Srivastava, B., Rossi, F., Towards composable bias rating of AI services (2018) Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, pp. 284-289; Carsten Stahl, B., Wright, D., Ethics and privacy in AI and big data: Implementing responsible research and innovation (2018) Ieee Security & Privacy, 16 (3), pp. 26-33. , 2018; Stalla-Bourdillon, S., Knight, A., Anonymous data v personal data-false debate: An EU perspective on anonymization, pseudonymization and personal data (2016) Wisconsin International Law Journal, 34, p. 284. , 2016; Su, D., Tri Huynh, H., Chen, Z., Lu, Y., Lu, W., Re-identification attack to privacy-preserving data analysis with noisy sample-mean (2020) Proceedings of the 26th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining, pp. 1045-1053; Sweeney, L., K-Anonymity: A model for protecting privacy (2002) International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 10 (5), pp. 557-570. , 2002; Theodorou, A., Dignum, V., Towards ethical and socio-legal governance in AI (2020) Nature Machine Intelligence, 2 (1), pp. 10-12. , 2020; Thomas, M., (2019) 6 Dangerous Risks of Artificial Intelligence, , https://builtin.com/artificial-intelligence/risks-of-artificial-intelligence, Retrieved November 2, 2021 from; Truex, S., Baracaldo, N., Anwar, A., Steinke, T., Ludwig, H., Zhang, R., Zhou, Y., A hybrid approach to privacy-preserving federated learning (2019) Proceedings of the 12th ACMWorkshop on Artificial Intelligence and Security, pp. 1-11; Tufekci, Z., Big questions for social media big data: Representativeness, validity and other methodological pitfalls (2014) Proceedings of the International Aaai Conference on Web and Social Media, 8; Turner, R., A model explanation system (2016) Proceedings of the 2016 Ieee 26th International Workshop on Machine Learning for Signal Processing (MLSP'16), pp. 1-6. , IEEE, Los Alamitos, CA; Tutt, A., An FDA for algorithms (2017) Administrative Law Review, 69, p. 83. , 2017; (2017) Top 10 Principles for Ethical Artificial Intelligence, , UNI Global Union, UNI Global Union, Nyon, Switzerland; Uslu, S., Kaur, D., Rivera, S.J., Durresi, A., Babbar-Sebens, M., Decision support system using trust planning among food-energy-water actors (2019) Proceedings of the International Conference on Advanced Information Networking and Applications, pp. 1169-1180; Uslu, S., Kaur, D., Rivera, S.J., Durresi, A., Babbar-Sebens, M., Trust-based gametheoretical decision making for food-energy-water management (2019) Proceedings of the International Conference on Broadband and Wireless Computing, Communication, and Applications, pp. 125-136; Uslu, S., Kaur, D., Rivera, S.J., Durresi, A., Babbar-Sebens, M., Trust-based decision making for food-energy-water actors (2020) Proceedings of the International Conference on Advanced Information Networking and Applications, pp. 591-602; Uslu, S., Kaur, D., Rivera, S.J., Durresi, A., Babbar-Sebens, M., Tilt, J.H., Control theoretical modeling of trust-based decision making in food-energy-water management (2020) Proceedings of the Conference on Complex, Intelligent, and Software Intensive Systems, pp. 97-107; Uslu, S., Kaur, D., Rivera, S.J., Durresi, A., Durresi, M., Babbar-Sebens, M., Trustworthy acceptance: A newmetric for trustworthy artificial intelligence used in decisionmaking in food-energywater sectors (2021) Proceedings of the 35th International Conference on Advanced Information Networking and Applications (AINA'21), pp. 208-219; Venkatesh, V., Thong L., J.Y., Xu, X., Consumer acceptance and use of information technology: Extending the unified theory of acceptance and use of technology (2012) Mis Quarterly, 36 (1), pp. 157-178. , 2012; Verma, S., Rubin, J., Fairness definitions explained (2018) Proceedings of the 2018 IEEE/ACM International Workshop on Software Fairness (FairWare'18), pp. 1-7. , IEEE, Los Alamitos, CA; Wachter, S., Mittelstadt, B., Russell, C., Counterfactual explanations without opening the black box: Automated decisions and the GDPR (2017) Harvard Journal of Law and Technology, 31, p. 841. , 2017; Wachter, S., Mittelstadt, B., Russell, C., (2020) Why Fairness Cannot Be Automated: Bridging the Gap between Eu Non-discrimination Law and Ai, , 2020, SSRN; Wang, Y., Wang, Y., Lin, T., Developing and validating a technology upgrade model (2018) International Journal of Information Management, 38 (1), pp. 7-26. , 2018; Welling, S.H., Refsgaard F., H.H., Brockhoff, P.B., Clemmensen, L.H., (2016) Forest Floor Visualizations of Random Forests, , https://arxiv.org/abs/1605.09196, 2016; Weyuker, E.J., On testing non-testable programs (1982) Computer Journal, 25 (4), pp. 465-470. , 1982; Wieringa, M., What to account for when accounting for algorithms: A systematic literature review on algorithmic accountability (2020) Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pp. 1-18; Williamson, O.E., Calculativeness, trust, and economic organization (1993) Journal of Law and Economics, 36 (1), pp. 453-486. , 1993; James Wilson, H., Daugherty, P.R., Collaborative intelligence: Humans and AI are joining forces (2018) Harvard Business Review, 96 (4), pp. 114-123. , 2018; Wright, D., A framework for the ethical impact assessment of information technology (2011) Ethics and Information Technology, 13 (3), pp. 199-226. , 2011; Wright, D., Friedewald, M., Gellert, R., Developing and testing a surveillance impact assessment methodology (2015) International Data Privacy Law, 5 (1), pp. 40-53. , 2015; Writer, N.D., Ahmed, S., Bajema, N.E., Bendett, S., Chang, B.A., Creemers, R., Demchak, C.C., (2019) Artificial Intelligence, China, Russia, and the Global Order Technological, Political, Global, and Creative Perspectives, , Technical Report. Air University Press, Maxwell AFB; Xie, X., Ho K., J.W., Murphy, C., Kaiser, G., Xu, B., Yueh Chen, T., Testing and validating machine learning classifiers by metamorphic testing (2011) Journal of Systems and Software, 84 (4), pp. 544-558. , 2011; Xu, K., Hoon Park, D., Yi, C., Sutton, C., (2018) Interpreting Deep Classifier by Visual Distillation of Dark Knowledge, , 2018; Yang, C., Rangarajan, A., Ranka, S., Global model interpretation via recursive partitioning (2018) Proceedings of the 2018 Ieee 20th International Conference on High Performance Computing and Communications, the Ieee 16th International Conference on Smart City, and the Ieee 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS'18), pp. 1563-1570. , IEEE, Los Alamitos, CA; Yeung, K., 'Hypernudge': Big data as a mode of regulation by design (2017) Information, Communication & Society, 20 (1), pp. 118-136. , 2017; Youl Youm, H., An overview of de-identification techniques and their standardization directions (2020) Ieice Transactions on Information and Systems, 103 (7), pp. 1448-1461. , 2020; Yu, H., Shen, Z., Miao, C., Leung, C., Lesser, V.R., Yang, Q., (2018) Building Ethics into Artificial Intelligence, , https://arxiv.org/abs/1812.02953, 2018; Bilal Zafar, M., Valera, I., Gomez Rogriguez, M., Gummadi, K.P., Fairness constraints: Mechanisms for fair classification (2017) Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, pp. 962-970; Zeng, Y., Lu, E., Huangfu, C., (2018) Linking Artificial Intelligence Principles, , https://arxiv.org/abs/1812.04814, 2018; Hu Zhang, B., Lemoine, B., Mitchell, M., Mitigating unwanted biases with adversarial learning (2018) Proceedings of the 2018 AAAI/ Acm Conference on AI, Ethics, and Society, pp. 335-340; Zhang, Y., Bellamy, R., Varshney, K., Joint optimization of AI fairness and utility: A humancentered approach (2020) Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, pp. 400-406; Zhao, G., Zhou, B., Wang, K., Jiang, R., Xu, M., Respond-CAM: Analyzing deep models for 3D imaging data by visualizations (2018) Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 485-492; Zhou, B., Sun, Y., Bau, D., Torralba, A., Interpretable basis decomposition for visual explanation (2018) Proceedings of the European Conference on Computer Vision (ECCV'18), pp. 119-134",,,,"Association for Computing Machinery",,,,,03600300,,ACSUE,,"English","ACM Comput Surv",Review,"Final","",Scopus,2-s2.0-85128190943
"Abdel-Mooty M.N., El-Dakhakhni W., Coulibaly P.","57224356796;12762086800;6602839517;","Community Resilience Classification Under Climate Change Challenges",2023,"Lecture Notes in Civil Engineering","240",,,"227","237",,,"10.1007/978-981-19-0507-0_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131122925&doi=10.1007%2f978-981-19-0507-0_21&partnerID=40&md5=c1e823726cbb123f569d484246feaaf8","Department of Civil Engineering, McMaster University, 1280 Main Street West, Hamilton, ON  L8S 4L7, Canada; Department of Civil Engineering, McMaster Institute for Multi-Hazard Systemic Risk Studies (INTERFACE), McMaster University, 1280 Main Street West, Hamilton, ON  L8S 4L7, Canada; Department of Civil Engineering, NSERC FloodNet, McMaster University, 1280 Main Street West, Hamilton, ON  L8S 4L7, Canada","Abdel-Mooty, M.N., Department of Civil Engineering, McMaster University, 1280 Main Street West, Hamilton, ON  L8S 4L7, Canada, Department of Civil Engineering, McMaster Institute for Multi-Hazard Systemic Risk Studies (INTERFACE), McMaster University, 1280 Main Street West, Hamilton, ON  L8S 4L7, Canada; El-Dakhakhni, W., Department of Civil Engineering, McMaster Institute for Multi-Hazard Systemic Risk Studies (INTERFACE), McMaster University, 1280 Main Street West, Hamilton, ON  L8S 4L7, Canada; Coulibaly, P., Department of Civil Engineering, NSERC FloodNet, McMaster University, 1280 Main Street West, Hamilton, ON  L8S 4L7, Canada","In the past decades, the United States of America and Canada have witnessed a continuous increase in the frequency and magnitude of climate change-induced natural disasters. These events include droughts, floods, wildfires, and most recently, tornadoes. In 2016, climate change induced damage was estimated to be $8.6 billion in Canada, while in the United States of America, floods are becoming one of the costliest and highest in occurrence of all climate change induced hazards, costing an average of $8 billion dollars annually. Also, hurricanes such as hurricane Sandy cost over $67 billion dollars of total damage, while more recently. hurricane Florence resulted in an estimated damage of $5 billion so far. It is thus clear that the effect of climate change is already costing North Americans billions of dollars annually, at an increasing rate. Coupled with climate change, the expansive developments of urban areas are causing a significant increase in flood-related disasters worldwide. However, most flood risk analysis and categorization efforts have been focused solely on the hydrologic features of flood hazards (e.g., inundation depth and duration) without considering the resulting long-term consequences in terms of losses and recovery time, and thus the community’s flood resilience. The aim of this study is to develop a flood resilience classification system at a community level that can be used in the development of disaster managerial insights and risk mitigation measures, to better prepare urban areas from future flood risks. This data-driven model will categorize communities using Machine learning classification techniques, bypassing the complexity and probabilistic nature of physics-based models. © 2023, Canadian Society for Civil Engineering.",,"Costs; Disasters; Flood control; Floods; Hazards; Hurricanes; Risk analysis; Risk assessment; Community resiliences; Drought/flood; Flood risk analysis; Florence; Induced damage; Natural disasters; North American; Risk categorization; United States of America; Urban areas; Climate change",,,,,"Natural Sciences and Engineering Research Council of Canada, NSERC","The work presented in this study supported by the Vanier Canada Graduate Scholarship (Vanier-CGS) awarded to the corresponding author, and the Natural Science and Engineering Research Council (NSERC) through the CaNRisk— Collaborative Research and Training Experience (CREATE) program. Additional support through the INViSiONLab and the INTERFACE Institute of McMaster university is also acknowledged.",,,,,,,,,,"Abdel-Mooty, M.N., Yosri, A., El-Dakhakhni, W., Coulibaly, P., Community flood resilience categorization framework (2021) Int J Disaster Risk Reduction, 61. , https://doi.org/10.1016/j.ijdrr.2021.102349; Alsabti, K., Ranka, S., Singh, V., (1997) An Efficient K-Means Clustering Algorithm; Bertilsson, L., Wiklund, K., de Moura Tebaldi, I., Rezende, O.M., Veról, A.P., Miguez, M.G., Urban flood resilience–a multi-criteria index to integrate flood resilience into urban planning (2019) J Hydrol, 573 (February 2016), pp. 970-982. , https://doi.org/10.1016/j.jhydrol.2018.06.052; Bruneau, M., Chang, S.E., Eguchi, R.T., Lee, G.C., O’Rourke, T.D., Reinhorn, A.M., Shinozuka, M., von Winterfeldt, D., A framework to quantitatively assess and enhance the seismic resilience of communities (2003) Earthq Spectra, 19 (4), pp. 733-752. , https://doi.org/10.1193/1.1623497; Cimellaro, G.P., Fumo, C., Reinhorn, A.M., Bruneau, M., Quantification of disaster resilience of health care facilities (2009) Mceer-09–0009, , http://mceer.buffalo.edu; Dunn, K., Process improvement using data. http://Learnche.Org/Pid, no (2019) January, p. 381. , http://learnche.org/Pid; Hartigan, J.A., Wong, M.A., (1979) A K-Means Clustering Algorithm. J R Stat Society Ser C (Appl Stat), 28 (1), pp. 100-108; Houghton, J.T., Jenkins, G.J., Ephraums, J.J., (1990) Climate Change: The IPCC Scientific Assessment; Leite, C., Oliveira, V., Miranda, I., Pereira, H., Cork oak and climate change: Disentangling drought effects on cork chemical composition (2020) Sci Rep, 10 (1), pp. 1-8. , https://doi.org/10.1038/s41598-020-64650-9; Levitus, S., Antonov, J., Boyer, T., Baranova, O., Garcia, H., Locarnini, R., Mishonov, A., NCEI ocean heat content, temperature anomalies, salinity anomalies, thermosteric sea level anomalies, halosteric sea level anomalies, and total steric sea level anomalies from 1955 to present calculated from in situ oceanographic subsurface profile data (2017) Natl Centres Environ Inf Dataset, , https://doi.org/10.7289/V53F4MVP; Lian, J., Xu, H., Xu, K., Ma, C., Optimal management of the flooding risk caused by the joint occurrence of extreme rainfall and high tide level in a coastal city (2017) Nat Hazards, 89 (1), pp. 183-200. , https://doi.org/10.1007/s11069-017-2958-4; Mathworks (2019) Deep Learning Toolbox: User’s Guide (R2019b), , https://www.mathworks.com/help/pdf_doc/deeplearning/nnet_ug.pdf, Massachusetts; Mcnicholas PD (2016) Model-based clustering. J Classif 373(November):331–373. https://doi. org/10.1007/s0035; Murdock, H.J., (2017) Resilience of Critical Infrastructure to Flooding: Quantifying the Resilience of Critical Infrastructure to Flooding in Toronto, , Canada; Nerem, R.S., Beckley, B.D., Fasullo, J.T., Hamlington, B.D., Masters, D., Mitchum, G.T., Climate-change–driven accelerated sea-level rise detected in the altimeter era (2018) Proc Natl Acad Sci USA, 115 (9), pp. 2022-2025. , https://doi.org/10.1073/pnas.1717312115; (2019) The Canadian Disaster Database, , https://www.publicsafety.gc.ca/cnt/rsrcs/cndn-dsstr-dtbs/index-en.aspx, Public Safety Canada; Tsesmelis, D.E., Karavitis, C.A., Oikonomou, P.D., Alexandris, S., Kosmas, C., Assessment of the vulnerability to drought and desertification characteristics using the standardized drought vulnerability index (SDVI) and the environmentally sensitive areas index (ESAI) (2019) Resources, 8 (1), pp. 1-19. , https://doi.org/10.3390/resources8010006; USGCRP (2018) Fourth national climate assessment: report-in-brief, vol II. https://doi.org/10. 1016/j.pbb.2008.09.016; Wagstaff, K., Cardie, C., Rogers, S., Schrödl, S., Constrained k-means clustering with background knowledge (2001) International Conference on Machine Learning ICML, pp. 577-584. , http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.4624&rep=rep1&type=pdf, pp; Wilby RL, Beven KJ, Reynard NS (2007) Climate change and fluvial flood risk in the UK: more of the same? Hydrol Process 2309(December 2007):2300–2309. https://doi.org/10.100 2/hyp; (2017) Climate Science Special Report: Fourth National Climate Assessment, 1. , https://doi.org/10.7930/J0J964J6, Wuebbles DJ, Fahey DW, Hibbard KA, Dokken DJ, Stewart BC, Maycock TK, vol, Washington, DC","Abdel-Mooty, M.N.; Department of Civil Engineering, 1280 Main Street West, Canada; email: abdelmom@mcmaster.ca","Walbridge S.Nik-Bakht M.Ng K.T.Shome M.Alam M.S.el Damatty A.Lovegrove G.",,"Springer Science and Business Media Deutschland GmbH","Canadian Society of Civil Engineering Annual Conference, CSCE 2021","26 May 2021 through 29 May 2021",,277909,23662557,9789811905063,,,"English","Lect. Notes Civ. Eng.",Conference Paper,"Final","",Scopus,2-s2.0-85131122925